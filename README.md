# ğŸ“„ Hybrid Text Summarizer Using LLM

**BART-large-CNN + Groq / Gemini Hybrid System**
**Akashchand Rajput â€” AI & Data Science Student, AIDTM College**
Gandhinagar, Gujarat, India Â· Feb 2026

---

## ğŸ“Œ Project Overview

This project implements a hybrid text summarization system that combines traditional transformer-based summarization with modern Large Language Models (LLMs).

It demonstrates how real-world NLP systems integrate:

* Extractive summarization
* Abstractive refinement
* Web scraping pipelines
* Multi-document processing
* Topic classification
* Evaluation using ROUGE-2

The system is built as an academic project showcasing practical AI system design.

---

## ğŸ¯ Why This Project Was Built

Modern news consumption involves large volumes of information from multiple sources. Manually reading and synthesizing articles is time-consuming.

This system aims to:

* Automatically extract content from news websites
* Produce concise fact-preserving summaries
* Combine multiple documents into a unified briefing
* Demonstrate hybrid NLP techniques used in industry

---

## ğŸ§  Hybrid Summarization Pipeline

```text
Input Text / News Article
        â†“
BART-large-CNN (compression)
        â†“
LLM Refinement (Groq or Gemini)
        â†“
Final Fact-Preserving Summary
```

### âœ… Why a Hybrid Approach?

Pure extractive models often lack readability, while pure LLM summaries may hallucinate facts.

Combining both provides:

* Structure + factual grounding (BART)
* Fluency + coherence (LLM)

---

## ğŸ” Why Each Technology Was Used

### ğŸ§¾ BART-large-CNN (Base Summarizer)

**Why used:**

* State-of-the-art transformer for summarization
* Pretrained specifically on news articles
* Produces reliable, structured summaries
* Works locally (no API required)
* Reduces input size before LLM processing

**Why not alternatives:**

* T5 â†’ Slower and requires careful prompting
* PEGASUS â†’ Heavy and less accessible on CPU
* GPT-style models â†’ Require API, not offline capable
* Extractive algorithms (TextRank, LexRank) â†’ Lower quality

---

### ğŸ¤– Groq Llama-3.1-8B (Fast LLM Option)

**Why used:**

* Extremely fast inference
* Good factual consistency
* Free tier available
* Suitable for real-time applications

**Why not larger models:**

* Larger LLMs increase latency
* Higher cost
* Not necessary for refinement tasks

---

### âœ¨ Google Gemini 1.5 Flash (Reasoning-Focused Option)

**Why used:**

* Strong reasoning capabilities
* Good language fluency
* Handles long context efficiently
* Alternative provider for comparison

**Why not Gemini Pro / larger versions:**

* Higher latency
* Greater resource usage
* Flash model is optimized for speed-quality balance

---

### ğŸŒ Web Scraping (Requests + BeautifulSoup)

**Why used:**

* Works across most websites
* Lightweight and flexible
* No browser automation required
* Suitable for structured content extraction

**Why not Selenium or browser automation:**

* Much slower
* Requires heavy dependencies
* Unnecessary for static news pages
* Not ideal for lightweight academic deployment

---

### ğŸ§© Domain-Specific Selectors + Fallbacks

**Why used:**

News sites use different HTML structures.

Solution implemented:

1. Site-specific selectors (high accuracy)
2. Generic selectors (broad coverage)
3. JSON-LD structured data extraction
4. Microdata fallback

This layered approach improves extraction success.

---

### ğŸ“š Multi-Document Processing

**Why implemented:**

Real-world scenarios often involve multiple sources.

Capabilities:

* Individual summaries
* Combined executive summary
* Cross-document insights

This simulates real analyst workflows.

---

### ğŸ·ï¸ News Classification via LLM

**Why used:**

Traditional classifiers require labeled datasets.

LLMs can perform zero-shot classification using natural language prompts, making them ideal for flexible categorization without additional training.

---

## ğŸŒ Advanced Web Scraping Features

Supports major Indian and international news publishers.

Key capabilities:

* 120+ CSS selector patterns
* JSON-LD structured data extraction
* Noise filtering (ads, navigation, spam)
* Multi-article homepage processing
* Exponential backoff for failed requests

---

## ğŸ“Š Evaluation Metrics (Static)

Metrics displayed in the application are **pre-computed and static**, not calculated in real time.

### âœ… ROUGE-2 (Bigram Overlap)

Chosen because:

* Standard metric for summarization evaluation
* Measures content similarity at phrase level
* Widely used in research papers

Example benchmark values:

| Model Variant | ROUGE-2 |
| ------------- | ------- |
| BART Only     | 0.212   |
| BART + Groq   | 0.235   |
| BART + Gemini | 0.248   |

Additional reported estimates:

* Fact preservation
* Numeric accuracy
* Inference time

---

## ğŸ–¥ï¸ Application Modules

### 1ï¸âƒ£ Web Scraping Module

* Input news homepage URL
* Extract multiple articles
* Generate summaries and categories

---

### 2ï¸âƒ£ Multi-Document Module

* Add custom documents
* Produce individual summaries
* Generate combined executive summary

---

### 3ï¸âƒ£ Dataset Demo (XSum)

* Uses BBC XSum dataset samples
* Compare generated summaries with reference summaries

---

### 4ï¸âƒ£ Evaluation Panel

* Displays static performance metrics
* Illustrates benefits of hybrid approach

---

## ğŸ—ï¸ System Architecture

```text
News URL / Input Text
        â†“
Link Discovery & Scraping
        â†“
Content Extraction & Cleaning
        â†“
BART-large-CNN Summarizer
        â†“
LLM Refinement (Groq / Gemini)
        â†“
Classification & Output
        â†“
Streamlit Dashboard
```

---

## ğŸš€ Installation & Setup

### Prerequisites

* Python 3.10+
* Minimum 8 GB RAM
* Internet connection for model download

---

### Create Virtual Environment

```bash
python -m venv textsum
textsum\Scripts\activate.bat
```

---

### Install Dependencies

```bash
pip install -r requirements.txt
```

---

### Run the Application

```bash
streamlit run app.py
```

Open in browser:

```
http://localhost:8501
```

---

### Optional API Keys

For LLM refinement:

* Groq â†’ https://console.groq.com
* Gemini â†’ https://aistudio.google.com

Without keys, the system falls back to BART-only summarization.

---

## âš™ï¸ Configuration Options

Sidebar controls allow:

* LLM provider selection
* Maximum articles to scrape
* Summary length (Short / Balanced / Detailed)
* API key input

---

## ğŸ§ª Use Cases

* News aggregation and briefing
* Research summarization
* Academic NLP demonstrations
* Information overload reduction
* Multi-source analysis

---

## ğŸ“¦ Requirements

Core libraries:

```
torch
transformers
streamlit
rouge-score
groq
google-generativeai
beautifulsoup4
requests
datasets
```

---

## ğŸ”§ Limitations

* Metrics are static (not live evaluation)
* Scraping success depends on website structure
* Requires internet for LLM features
* Very long articles are truncated

---

## ğŸ‘¨â€ğŸ“ Author

**Akashchand Rajput**
AI & Data Science Student
AIDTM College
Gandhinagar, Gujarat, India

---

## ğŸ“„ License

MIT License â€” Free for academic and personal use.

---

## â­ Acknowledgements

* Hugging Face Transformers
* Meta BART model
* Groq LLM API
* Google Gemini API
* BBC XSum Dataset
* Streamlit Framework

---

*This project demonstrates how modern NLP systems combine traditional transformer models with LLMs to achieve high-quality summarization.*
